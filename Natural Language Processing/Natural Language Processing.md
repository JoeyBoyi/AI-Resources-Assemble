# Nature Language Processing

- Generating Wikipedia by Summarizing Long Sequences. [`arxiv`](https://arxiv.org/abs/1801.10198)
- Neural Relational Inference for Interacting Systems. [`arxiv`](https://arxiv.org/abs/1802.04687), [`code`](https://github.com/ethanfetaya/nri)


## Neural Image Caption (NIC)

- Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. [`arxiv`](https://arxiv.org/abs/1502.03044), [`code`](https://github.com/kelvinxu/arctic-captions)
- Show and Tell: A Neural Image Caption Generator. [`arxiv`](https://arxiv.org/abs/1411.4555)
- Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge. (Short Version). [`arxiv`](http://arxiv.org/abs/1609.06647), [`code`](https://github.com/tensorflow/models/tree/master/research/im2txt)


## Text Classification

- A C-LSTM Neural Network for Text Classification [`arxiv`](https://arxiv.org/abs/1511.08630), [`code`](https://github.com/zackhy/TextClassification) :star:
- Recurrent Convolutional Neural Networks for Text Classification [`google scholar`](chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html?file=https%3A%2F%2Fwww.aaai.org%2Focs%2Findex.php%2FAAAI%2FAAAI15%2Fpaper%2Fdownload%2F9745%2F9552), [`code`](https://github.com/jiegzhan/multi-class-text-classification-cnn-rnn)
- Distributed Representations of Sentences and Documents [`arxiv`](https://arxiv.org/abs/1405.4053)
- Hierarchical attention networks for document classification [`google scholar`](chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html?file=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FN16-1174)
- Very Deep Convolutional Networks for Text Classification [`arxiv`](https://arxiv.org/abs/1606.01781)


## Text Summarization

-  A Neural Attention Model for Abstractive Sentence Summarization [`arxiv`](https://arxiv.org/abs/1509.00685) 
-  Abstractive Sentence Summarization with Attentive Recurrent Neural Networks [`google scholar`](chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html?file=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FN16-1012)


## Sequence to Sequence model (Seq2Seq)

- Convolutional Sequence to Sequence Learning [`arxiv`](https://arxiv.org/abs/1705.03122)
- Attention Is All You Need [`arxiv`](https://arxiv.org/abs/1706.03762) :star:
- Massive Exploration of Neural Machine Translation Architectures [`arxiv`](https://arxiv.org/abs/1703.03906), [`code`](https://github.com/google/seq2seq)


## Named Entity Recognition (NER)

- [2017] Semi-supervised sequence tagging with bidirectional language models [`arxiv`](https://arxiv.org/abs/1705.00108)
- [2018] Chinese NER Using Lattice LSTM. [`arxiv`](https://arxiv.org/pdf/1805.02023.pdf) [`code`](https://github.com/jiesutd/LatticeLSTM)
- [2016] Neural Architectures for Named Entity Recognition [`arxiv`](https://arxiv.org/abs/1603.01360), [`LSTM-CRF`](https://github.com/glample/tagger), [`Stack-LSTM`](https://github.com/clab/stack-lstm-ner)


## Semantic Analysis

- [2015] Multi-Perspective Sentence Similarity Modeling with Convolutional Neural Network [`PDF`](http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP181.pdf), [`Analysis of Thesis 01`](http://blog.csdn.net/liuchonge/article/details/62424805), [`Analysis of Thesis 02`](http://blog.csdn.net/liuchonge/article/details/64128870), [`Analysis of Thesis 03`](http://blog.csdn.net/liuchonge/article/details/64440110), [`code`](https://github.com/Fengfeng1024/MPCNN), [`Reference`](https://github.com/lc222/MPCNN-sentence-similarity-tensorflow)
- SLING: A framework for frame semantic parsing [`arxiv`](http://arxiv.org/abs/1710.07032), [`code`](https://github.com/google/sling)
- An efficient framework for learning sentence representations [`arxiv`](https://arxiv.org/pdf/1803.02893.pdf), [`code`](https://github.com/lajanugen/S2V)
- Skip-Thought Vectors [`arxiv`](https://arxiv.org/abs/1506.06726), [`code`](https://github.com/tensorflow/models/tree/master/research/skip_thoughts)
- Universal Sentence Encoder [`arxiv`](https://arxiv.org/abs/1803.11175), [`code`](https://tfhub.dev/google/universal-sentence-encoder/1), [`code hub`](https://github.com/tensorflow/hub)
- Short text understanding through lexical-semantic analysis [`google scholar`](chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html?file=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fwp-content%2Fuploads%2F2016%2F02%2Fconceptualization.pdf)
- [2018] Learning Semantic Textual Similarity from Conversations [`arxiv`](https://arxiv.org/abs/1804.07754), [`code`]( https://github.com/tensorflow/tensor2tensor)

## Syntactic parsing (divergence of dependency) (Natural language understanding (NLU))

- syntaxnet [`code`](https://github.com/tensorflow/models/tree/master/research/syntaxnet)


## Question answering (Q&A)
- 
